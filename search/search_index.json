{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Inicio","text":"<p> Asignatura: Devops &amp; Cloud</p> <p> Alumno: Carlos Grande N\u00fa\u00f1ez</p> <p> Fecha: 23/03/25</p> <p>El informe en PDF ha sido generado a partir de la documentaci\u00f3n escrita en Markdown utilizando MkDocs, una librer\u00eda escrita en Python que me parece muy interesante y que uso habitualmente en mi d\u00eda a d\u00eda. Adem\u00e1s, el informe completo se encuentra disponible online a trav\u00e9s de GitHub Pages, recomiendo acceder a la versi\u00f3n online ya que considero que es mucho m\u00e1s \u00e1gil su lectura.</p> <p> Ir a la versi\u00f3n online</p>"},{"location":"#introduccion","title":"Introducci\u00f3n","text":"<p>Este repositorio contiene la soluci\u00f3n del Caso Pr\u00e1ctico 2, en el cual se ha desplegado una infraestructura en Microsoft Azure de forma automatizada utilizando Terraform y Ansible. Se incluyen configuraciones para la creaci\u00f3n de recursos en la nube, instalaci\u00f3n de servicios y despliegue de aplicaciones en contenedores con almacenamiento persistente.</p> <p></p>"},{"location":"#objetivos","title":"Objetivos","text":"<ul> <li>Crear infraestructura de forma automatizada en un proveedor de Cloud p\u00fablica.</li> <li>Utilizar herramientas de gesti\u00f3n de la configuraci\u00f3n para automatizar la instalaci\u00f3n y configuraci\u00f3n de servicios.</li> <li>Desplegar mediante un enfoque totalmente automatizado aplicaciones en forma de contenedor sobre el sistema operativo.</li> <li>Desplegar mediante un enfoque totalmente automatizado aplicaciones que hagan uso de almacenamiento persistente sobre una plataforma de orquestaci\u00f3n de contenedores.</li> </ul>"},{"location":"informe/","title":"Informe","text":"<p>Este informe documenta la entrega del Caso Pr\u00e1ctico 2 de la asignatura DevOps &amp; Cloud del programa avanzado DevOps de la UNIR. El contenido del informe se estructura en las siguientes secciones:  </p> <ul> <li>Arquitectura: Descripci\u00f3n de los componentes desplegados y su configuraci\u00f3n.  </li> <li>Despliegue: Ejecuci\u00f3n pr\u00e1ctica de la infraestructura y su configuraci\u00f3n.  </li> <li>Evidencias: Recopilaci\u00f3n de pruebas de funcionamiento y validaciones.  </li> <li>Licencia: Definici\u00f3n del marco legal de uso.  </li> <li>Referencias: Fuentes utilizadas en el desarrollo del ejercicio.  </li> </ul> <p>Para la generaci\u00f3n del informe, se ha utilizado MkDocs, una librer\u00eda de Python para la creaci\u00f3n de documentaci\u00f3n t\u00e9cnica (MkDocs, s.f.), junto con el plugin WithPDF, que permite la exportaci\u00f3n a formato PDF (WithPDF, s.f.). Esta elecci\u00f3n responde a la naturaleza del caso pr\u00e1ctico, en el que una de las tareas consiste en desplegar una imagen est\u00e1tica de una web en Nginx sin persistencia. Dado que MkDocs genera HTML est\u00e1tico, se ha integrado su uso dentro del ejercicio para la documentaci\u00f3n y su despliegue.</p>"},{"location":"informe/#codigo-fuente","title":"Codigo fuente","text":"<p> Acceso al repositorio</p>"},{"location":"informe/#estructura-del-repositorio","title":"Estructura del repositorio","text":"<p>El proyecto se organiza en tres grandes bloques: infraestructura, despliegue y documentaci\u00f3n. A continuaci\u00f3n se resume su estructura principal:</p> <pre><code>\ud83d\udce6 repo-root\n\u251c\u2500\u2500 terraform/        # C\u00f3digo para el despliegue de la infraestructura (ACR, VM, AKS)\n\u251c\u2500\u2500 ansible/          # Playbooks y roles para configurar la VM y desplegar en AKS\n\u251c\u2500\u2500 docs/             # Documentaci\u00f3n del proyecto (MkDocs)\n\u251c\u2500\u2500 site/             # Sitio est\u00e1tico generado de la documentaci\u00f3n\n\u251c\u2500\u2500 setup.sh          # Script para exportar variables tras despliegue\n\u251c\u2500\u2500 mkdocs.yml        # Configuraci\u00f3n de MkDocs\n\u251c\u2500\u2500 Dockerfile.docs   # Dockerfile para generar la imagen de documentaci\u00f3n\n\u251c\u2500\u2500 requirements.txt  # Dependencias de Python\n\u251c\u2500\u2500 README.md         # Descripci\u00f3n general del proyecto\n\u2514\u2500\u2500 LICENSE           # Licencia del repositorio\n</code></pre>"},{"location":"informe/despliegue/","title":"Despliegue","text":"<p>A continuaci\u00f3n, se explica c\u00f3mo reproducir los pasos necesarios para llevar a cabo el caso pr\u00e1ctico sobre el repositorio. Se detallan las instrucciones para:</p> <ul> <li>1. Despliegue de la infraestructura</li> <li>2. Publicaci\u00f3n de las imagenes</li> <li>3. Configuraci\u00f3n de la VM</li> <li>4. Configuraci\u00f3n del AKS</li> </ul>"},{"location":"informe/despliegue/#despliegue-de-la-infraestructura","title":"Despliegue de la infraestructura","text":"<p>El despliegue de la infraestructura se realiza con Terraform desde la m\u00e1quina local, asegurando que la configuraci\u00f3n es v\u00e1lida antes de aplicar los cambios y provisionar los recursos necesarios.</p> <ol> <li> <p>Inicializa terraform en el directorio de ficheros terraform.</p> <p><pre><code>terraform -chdir=./terraform init\n</code></pre> Output: <code>Terraform has been successfully initialized!</code></p> </li> <li> <p>Ejecuta la validaci\u00f3n de los ficheros generados con el siguiente comando:</p> <p><pre><code>terraform validate\n</code></pre> output: <code>Success! The configuration is valid.</code></p> </li> <li> <p>Despliega la infraestructura con el siguiente comando, por defecto se despliega en dev. Siempre puedes a\u00f1adir el flag <code>-var=\"environment=pro\"</code> para especificar un entorno entre <code>dev|pre|pro</code></p> <pre><code>terraform -chdir=./terraform apply --auto-approve\n</code></pre> </li> </ol> <p>Automatizaci\u00f3n de variables</p> <p>Tras el despliegue de toda la infraestructura se generan autom\u00e1ticamente las variables globales necesarias para poder realizar lo que queda del ejercicio ejecutando el fichero <code>setup.sh</code>.</p> <pre><code>source setup.sh\n</code></pre>"},{"location":"informe/despliegue/#publicacion-de-las-imagenes","title":"Publicaci\u00f3n de las imagenes","text":""},{"location":"informe/despliegue/#publicacion-de-las-imagenes-mediante-ansible","title":"Publicaci\u00f3n de las im\u00e1genes mediante Ansible","text":"<p>Para publicar im\u00e1genes en el ACR utilizando Ansible, se ha creado un playbook llamado <code>publish-images.yaml</code>. Para llevar a cabo su ejecuci\u00f3n, es necesario es necesario ejecutar desde el directorio de ansible el siguiente comando.</p> <pre><code>ansible-playbook publish_images.yml -i hosts.yml --ask-vault-pass\n</code></pre> <p>Este comando construye la imagen de MkDocs, descarga la imagen p\u00fablica de StackEdit y publica ambas im\u00e1genes en el ACR desde la VM.</p>"},{"location":"informe/despliegue/#publicacion-mediante-github-actions-fuera-de-alcance","title":"Publicaci\u00f3n mediante Github Actions (fuera de alcance)","text":"<p>En este apartado se explica la publicaci\u00f3n de im\u00e1genes en el ACR utilizando GitHub Actions. Aunque no formaba parte del alcance del ejercicio, se ha implementado este m\u00e9todo para probar un flujo habitual en proyectos donde un repositorio genera y publica im\u00e1genes de contenedor tras una release.</p> <p>La publicaci\u00f3n de la imagen se automatiza mediante el workflow <code>Publish mkdocs image to ACR</code> de GitHub Actions, que env\u00eda la imagen al Azure Container Registry (ACR). Para ello, se deben proporcionar las credenciales adecuadas y validar la ejecuci\u00f3n del proceso.</p> <ol> <li> <p>Rellenar los datos del formulario del workflow con username y pwd del ACR desplegado en Azure.</p> Visualizar usuario y contrase\u00f1a del ACR <p>Siempre puedes ejecutar este comando para recuperar el usuario y la contrase\u00f1a del ACR.</p> <pre><code>az acr credential show --name acrweucp2dev --query \"[username, passwords[0].value]\" -o tsv\n</code></pre> <p></p> </li> <li> <p>Ejecutar workflow y validar la correcta ejecuci\u00f3n del job</p> </li> </ol>"},{"location":"informe/despliegue/#configuracion-de-la-vm","title":"Configuraci\u00f3n de la VM","text":"<p>La configuraci\u00f3n de la VM se llevar\u00e1 a cabo desde la m\u00e1quina local utilizando Ansible, accediendo por SSH para realizar comprobaciones y garantizar el correcto despliegue del entorno.</p> <ol> <li> <p>Comprobar conexi\u00f3n a la VM por SSH</p> <pre><code>ssh -i ~/.ssh/az_unir_rsa charlstown@${VM_IP}\nexit\n</code></pre> </li> <li> <p>Ejecutar ansible apuntando a la VM. Asegurarse que el comando se ejecuta desde <code>./ansible</code>. Para forzar ansible a recrear todo desde el principio es posible usar los argumentos <code>--force-handlers</code> y <code>--extra-vars \"recreate=true\"</code>.</p> <pre><code>ansible-playbook ansible/playbook.yml -i ansible/hosts.yml --extra-vars \"@ansible/vars.yml\" --ask-vault-pass\n</code></pre> <p>Este playbook se ejecuta apuntando a un Vault de ansible donde se han guardado las credenciales usadas para crear el fichero <code>htpasswd.users</code> en la carpeta <code>/etc/nginx/auth/htpasswd.users</code> de la VM.</p> Mostrar contrase\u00f1as guardadas en el vault <p>Para visualizar las contrase\u00f1as guardadas en el vault puedes ejecutar el comando: <pre><code>ansible-vault view secrets.yml\n</code></pre></p> </li> </ol>"},{"location":"informe/despliegue/#configuracion-del-aks","title":"Configuraci\u00f3n del AKS","text":"<p>El despliegue de la aplicaci\u00f3n en el cl\u00faster de Kubernetes se realiza mediante Ansible, aplicando los manifiestos necesarios para crear el namespace, el deployment, el PersistentVolumeClaim, el Service y el secret de acceso al ACR. Todo el proceso queda automatizado en el playbook <code>playbook_aks.yml</code>.</p> <ol> <li> <p>Descargar credenciales del AKS para interactuar con el cl\u00faster desde kubectl.</p> <p>El siguiente comando guarda las credenciales del AKS en <code>/home/&lt;USER&gt;/.kube/config</code> y marca como contexto el AKS seleccionado.</p> <pre><code>az aks get-credentials --resource-group rg-weu-cp2-dev --name aks-weu-cp2-dev\n</code></pre> </li> <li> <p>Ejecutar el playbook de Ansible para desplegar la aplicaci\u00f3n en AKS. Este comando debe lanzarse desde la ra\u00edz del proyecto.</p> <pre><code>ansible-playbook playbook_aks.yml -i hosts.yml --ask-vault-pass\n</code></pre> </li> <li> <p>Para obtener la IP p\u00fablica del servicio y acceder a la aplicaci\u00f3n desplegada, ejecuta el siguiente comando.</p> <pre><code>kubectl get svc stackedit-service -n cp2 -o jsonpath=\"{.status.loadBalancer.ingress[0].ip}\"\n</code></pre> <p>La aplicaci\u00f3n estar\u00e1 disponible en esa direcci\u00f3n IP a trav\u00e9s del puerto 80.</p> </li> </ol> <p>\ud83d\ude80 Con estos pasos, se completa el despliegue y configuraci\u00f3n \u00edntegra del caso pr\u00e1ctico: se ha provisionado toda la infraestructura necesaria, se han publicado las im\u00e1genes de contenedor en el ACR, y se ha puesto en marcha tanto la VM como el cl\u00faster de AKS. El entorno queda totalmente funcional, con los contenedores desplegados y ejecut\u00e1ndose a partir de sus respectivas im\u00e1genes.</p>"},{"location":"informe/evidencias/","title":"Evidencias","text":"<p>A continuaci\u00f3n, se exponen las evidencias de los procesos empleados para realizar la pr\u00e1ctica.</p> <ul> <li>1. Despliegue de la infraestructura</li> <li>2. Publicaci\u00f3n de las imagenes</li> <li>3. Despliegue en la VM</li> <li>4. Despliegue en el AKS</li> </ul>"},{"location":"informe/evidencias/#despliegue-de-la-infraestructura","title":"Despliegue de la infraestructura","text":"<p>En esta secci\u00f3n se muestran los logs los principales comandos ejecutados y algunas capturas que demuestran la correcta ejecuci\u00f3n del caso pr\u00e1ctico.</p> <p>Lanzamos un <code>terraform plan</code> para comprobar todos los recursos.</p> <pre><code>terraform -chdir=./terraform plan\n</code></pre> output<pre><code>Terraform used the selected providers to generate the following execution plan.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # local_file.ansible_inventory will be created\n  + resource \"local_file\" \"ansible_inventory\" {\n      + content              = (sensitive value)\n      + content_base64sha256 = (known after apply)\n      + content_base64sha512 = (known after apply)\n      + content_md5          = (known after apply)\n      + content_sha1         = (known after apply)\n      + content_sha256       = (known after apply)\n      + content_sha512       = (known after apply)\n      + directory_permission = \"0777\"\n      + file_permission      = \"0777\"\n      + filename             = \"../ansible/hosts.yml\"\n      + id                   = (known after apply)\n    }\n\n  # module.aks.azurerm_kubernetes_cluster.aks will be created\n  + resource \"azurerm_kubernetes_cluster\" \"aks\" {\n      + api_server_authorized_ip_ranges     = (known after apply)\n      + current_kubernetes_version          = (known after apply)\n      + dns_prefix                          = \"aksweucp2\"\n      + fqdn                                = (known after apply)\n      + http_application_routing_zone_name  = (known after apply)\n      + id                                  = (known after apply)\n      + image_cleaner_enabled               = false\n      + image_cleaner_interval_hours        = 48\n      + kube_admin_config                   = (sensitive value)\n      + kube_admin_config_raw               = (sensitive value)\n      + kube_config                         = (sensitive value)\n      + kube_config_raw                     = (sensitive value)\n      + kubernetes_version                  = (known after apply)\n      + location                            = \"westeurope\"\n      + name                                = \"aks-weu-cp2-dev\"\n      + node_resource_group                 = (known after apply)\n      + node_resource_group_id              = (known after apply)\n      + oidc_issuer_url                     = (known after apply)\n      + portal_fqdn                         = (known after apply)\n      + private_cluster_enabled             = false\n      + private_cluster_public_fqdn_enabled = false\n      + private_dns_zone_id                 = (known after apply)\n      + private_fqdn                        = (known after apply)\n      + public_network_access_enabled       = true\n      + resource_group_name                 = \"rg-weu-cp2-dev\"\n      + role_based_access_control_enabled   = true\n      + run_command_enabled                 = true\n      + sku_tier                            = \"Standard\"\n      + support_plan                        = \"KubernetesOfficial\"\n      + tags                                = {\n          + \"environment\" = \"casopractico2\"\n        }\n      + workload_identity_enabled           = false\n\n      + api_server_access_profile (known after apply)\n\n      + auto_scaler_profile (known after apply)\n\n      + default_node_pool {\n          + kubelet_disk_type    = (known after apply)\n          + max_pods             = (known after apply)\n          + name                 = \"default\"\n          + node_count           = 1\n          + node_labels          = (known after apply)\n          + orchestrator_version = (known after apply)\n          + os_disk_size_gb      = 30\n          + os_disk_type         = \"Managed\"\n          + os_sku               = (known after apply)\n          + scale_down_mode      = \"Delete\"\n          + type                 = \"VirtualMachineScaleSets\"\n          + ultra_ssd_enabled    = false\n          + vm_size              = \"Standard_B2s\"\n          + workload_runtime     = (known after apply)\n        }\n\n      + identity {\n          + principal_id = (known after apply)\n          + tenant_id    = (known after apply)\n          + type         = \"SystemAssigned\"\n        }\n\n      + kubelet_identity (known after apply)\n\n      + network_profile (known after apply)\n\n      + windows_profile (known after apply)\n    }\n\n  # module.aks.azurerm_role_assignment.acr_pull will be created\n  + resource \"azurerm_role_assignment\" \"acr_pull\" {\n      + id                               = (known after apply)\n      + name                             = (known after apply)\n      + principal_id                     = (known after apply)\n      + principal_type                   = (known after apply)\n      + role_definition_id               = (known after apply)\n      + role_definition_name             = \"AcrPull\"\n      + scope                            = (known after apply)\n      + skip_service_principal_aad_check = (known after apply)\n    }\n\n  # module.container_registry.azurerm_container_registry.acr will be created\n  + resource \"azurerm_container_registry\" \"acr\" {\n      + admin_enabled                 = true\n      + admin_password                = (sensitive value)\n      + admin_username                = (known after apply)\n      + encryption                    = (known after apply)\n      + export_policy_enabled         = true\n      + id                            = (known after apply)\n      + location                      = \"westeurope\"\n      + login_server                  = (known after apply)\n      + name                          = \"acrweucp2dev\"\n      + network_rule_bypass_option    = \"AzureServices\"\n      + network_rule_set              = (known after apply)\n      + public_network_access_enabled = true\n      + resource_group_name           = \"rg-weu-cp2-dev\"\n      + retention_policy              = (known after apply)\n      + sku                           = \"Basic\"\n      + tags                          = {\n          + \"environment\" = \"casopractico2\"\n        }\n      + trust_policy                  = (known after apply)\n      + zone_redundancy_enabled       = false\n    }\n\n  # module.virtual_machine.azurerm_linux_virtual_machine.vm will be created\n  + resource \"azurerm_linux_virtual_machine\" \"vm\" {\n      + admin_username                                         = \"charlstown\"\n      + allow_extension_operations                             = true\n      + bypass_platform_safety_checks_on_user_schedule_enabled = false\n      + computer_name                                          = (known after apply)\n      + disable_password_authentication                        = true\n      + disk_controller_type                                   = (known after apply)\n      + extensions_time_budget                                 = \"PT1H30M\"\n      + id                                                     = (known after apply)\n      + location                                               = \"westeurope\"\n      + max_bid_price                                          = -1\n      + name                                                   = \"vm-weu-cp2-docs-dev\"\n      + network_interface_ids                                  = (known after apply)\n      + patch_assessment_mode                                  = \"ImageDefault\"\n      + patch_mode                                             = \"ImageDefault\"\n      + platform_fault_domain                                  = -1\n      + priority                                               = \"Regular\"\n      + private_ip_address                                     = (known after apply)\n      + private_ip_addresses                                   = (known after apply)\n      + provision_vm_agent                                     = true\n      + public_ip_address                                      = (known after apply)\n      + public_ip_addresses                                    = (known after apply)\n      + resource_group_name                                    = \"rg-weu-cp2-dev\"\n      + size                                                   = \"Standard_B1ls\"\n      + tags                                                   = {\n          + \"environment\" = \"casopractico2\"\n        }\n      + virtual_machine_id                                     = (known after apply)\n      + vm_agent_platform_updates_enabled                      = false\n\n      + admin_ssh_key {\n          + public_key = &lt;&lt;-EOT\n                \\*\\*\\*\n            EOT\n          + username   = \"charlstown\"\n        }\n\n      + os_disk {\n          + caching                   = \"ReadWrite\"\n          + disk_size_gb              = (known after apply)\n          + name                      = (known after apply)\n          + storage_account_type      = \"Standard_LRS\"\n          + write_accelerator_enabled = false\n        }\n\n      + source_image_reference {\n          + offer     = \"0001-com-ubuntu-server-jammy\"\n          + publisher = \"Canonical\"\n          + sku       = \"22_04-lts-gen2\"\n          + version   = \"latest\"\n        }\n\n      + termination_notification (known after apply)\n    }\n\n  # module.virtual_machine.azurerm_network_interface.nic will be created\n  + resource \"azurerm_network_interface\" \"nic\" {\n      + accelerated_networking_enabled = (known after apply)\n      + applied_dns_servers            = (known after apply)\n      + dns_servers                    = (known after apply)\n      + enable_accelerated_networking  = (known after apply)\n      + enable_ip_forwarding           = (known after apply)\n      + id                             = (known after apply)\n      + internal_domain_name_suffix    = (known after apply)\n      + ip_forwarding_enabled          = (known after apply)\n      + location                       = \"westeurope\"\n      + mac_address                    = (known after apply)\n      + name                           = \"vm-weu-cp2-docs-dev-nic\"\n      + private_ip_address             = (known after apply)\n      + private_ip_addresses           = (known after apply)\n      + resource_group_name            = \"rg-weu-cp2-dev\"\n      + tags                           = {\n          + \"environment\" = \"casopractico2\"\n        }\n      + virtual_machine_id             = (known after apply)\n\n      + ip_configuration {\n          + gateway_load_balancer_frontend_ip_configuration_id = (known after apply)\n          + name                                               = \"internal\"\n          + primary                                            = (known after apply)\n          + private_ip_address                                 = (known after apply)\n          + private_ip_address_allocation                      = \"Dynamic\"\n          + private_ip_address_version                         = \"IPv4\"\n          + public_ip_address_id                               = \"/subscriptions/fb24fc1f-67e2-4871-8be2-c10a36e74c93/resourceGroups/rg-weu-cp2-dev/providers/Microsoft.Network/publicIPAddresses/vm-weu-cp2-docs-dev-public-ip\"\n          + subnet_id                                          = \"/subscriptions/fb24fc1f-67e2-4871-8be2-c10a36e74c93/resourceGroups/rg-weu-cp2-dev/providers/Microsoft.Network/virtualNetworks/vnet-weu-cp2-dev/subnets/subnet-weu-cp2-dev\"\n        }\n    }\n\nPlan: 6 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + acr_login_server = (known after apply)\n  + acr_password     = (sensitive value)\n  + acr_username     = (known after apply)\n</code></pre>"},{"location":"informe/evidencias/#creacion-de-los-grupos-de-recursos","title":"Creaci\u00f3n de los grupos de recursos","text":"<p>Tras ejecutar el comando de <code>terraform apply</code> podremos ver en el apartado Resource groups los siguientes RGs.</p> <pre><code>terraform -chdir=./terraform apply --auto-approve\n</code></pre> <p></p> <ul> <li>MC_rg-weu-cp2-dev_aks-weu-cp2-dev_westeurope: Grupo de recursos gestionado autom\u00e1ticamente por Azure para almacenar los nodos y configuraciones internas del AKS.  </li> <li>NetworkWatcherRG: Grupo de recursos creado por Azure para herramientas de monitoreo y diagn\u00f3stico de red.  </li> <li>rg-weu-cp2-dev: Grupo de recursos principal donde se despliegan la VM, el ACR y el AKS mediante Terraform.</li> </ul>"},{"location":"informe/evidencias/#rg-weu-cp2-dev","title":"rg-weu-cp2-dev","text":"<p>El <code>rg-weu-cp2-dev</code> contiene todos los recursos declarados en nuestros ficheros de terraform.</p> <p></p>"},{"location":"informe/evidencias/#creacion-del-acr","title":"Creaci\u00f3n del ACR","text":"<p>Desde el portal de Azure podemos observar como el servicio de contenedores (ACR) se ha creado correctamente bajo los par\u00e1metros definidos en los ficheros terraform.</p> <p></p> <pre><code>az acr list --query \"[?name=='acrweucp2dev']\" --output table\n</code></pre> <p>Tras lanzar este comando recibimos esta salida por consola:</p> <p>Here is the Markdown code for the table:</p> Name Location LoginServer CreationDate ProvisioningState AdminUserEnabled DataEndpointEnabled PublicNetworkAccess NetworkRuleBypassOptions ZoneRedundancy AnonymousPullEnabled MetadataSearch ResourceGroup acrweucp2dev westeurope acrweucp2dev.azurecr.io 2025-03-16T20:22:34.983350+00:00 Succeeded True False Enabled AzureServices Disabled False Disabled rg-weu-cp2-dev <p>Tambi\u00e9n podemos comprobar que se ha creado correctamente iniciando sesi\u00f3n en el ACR mediante el comando <code>az acr login --name acrweucp2dev</code> que devuelve la siguiente salida:</p> <p></p>"},{"location":"informe/evidencias/#creacion-de-la-vm","title":"Creaci\u00f3n de la VM","text":"<p>Desde el portal de Azure podemos observar como la VM se ha creado correctamente bajo los par\u00e1metros definidos en los ficheros terraform.</p> <p></p> <p>Para comprobar que la VM est\u00e1 levantada podemos acceder por ssh usando la clave p\u00fablica que le pasamos en el momento del despliegue con terraform y la IP p\u00fablica publicada en los outputs.</p> <p>La IP P\u00fablica la podemos extraer de los outputs generados de terraform</p> <pre><code>terraform output\n</code></pre> <p></p> <p>Si hacemos ssh contra esa IP y con la clave p\u00fablica que pasamos en el momento de craci\u00f3n podremos acceder a la VM.</p> <pre><code>ssh -i ~/.ssh/az_unir_rsa charlstown@13.81.82.89\n</code></pre> <p></p>"},{"location":"informe/evidencias/#creacion-del-aks","title":"Creaci\u00f3n del AKS","text":"<p>Desde el portal de Azure podemos observar como el servicio de Kubernetes (AKS) se ha creado correctamente bajo los par\u00e1metros definidos en los ficheros terraform.</p> <p></p> <p>Podemos comprobar el estado del AKS en Azure mediante el siguiente comando:</p> <pre><code>az aks show --resource-group rg-weu-cp2-dev --name aks-weu-cp2-dev --output table\n</code></pre> <p>Here is the markdown code for your table:</p> Name Location ResourceGroup KubernetesVersion CurrentKubernetesVersion ProvisioningState Fqdn aks-weu-cp2-dev westeurope rg-weu-cp2-dev 1.30 1.30.9 Succeeded aksweucp2-1fslhh1t.hcp.westeurope.azmk8s.io <p>Para probar desde local que podemos acceder al cluster de Kubernetes, podemos realizar los siguientes comandos.</p> Credenciales de acceso <pre><code>az aks get-credentials --resource-group rg-weu-cp2-dev --name aks-weu-cp2-dev\n</code></pre> <p>Con este comando podemos ver los nodos del cluster y si el AKS est\u00e1 levantado, deber\u00edan aparecer con estado Ready.</p> <pre><code>kubectl get nodes\n</code></pre> <p></p> <p>Con el siguiente comando podemos listar los pods internos del cl\u00faster (como CoreDNS, metric-server, etc.). Si est\u00e1n en Running, el cl\u00faster funciona correctamente.</p> <pre><code>kubectl get pods -n kube-system\n</code></pre> <p></p>"},{"location":"informe/evidencias/#publicacion-de-las-imagenes","title":"Publicaci\u00f3n de las imagenes","text":""},{"location":"informe/evidencias/#publicacion-de-imagenes-mediante-ansible","title":"Publicaci\u00f3n de im\u00e1genes mediante Ansible","text":"<p>Tras ejecutar el playbook <code>publish_images.yml</code> de Asnible con el comando:</p> <pre><code>ansible-playbook ansible/publish_images.yml -i an\nsible/hosts.yml --extra-vars \"@ansible/vars.yml\" --ask-vault-pass\n</code></pre> <p>Podemos ver como se ejecuta el rol de ACR de la carpeta Ansible ejecutando las tareas sin errores.</p> <p></p>"},{"location":"informe/evidencias/#publicacion-mediante-github-actions-fuera-de-alcance","title":"Publicaci\u00f3n mediante Github Actions (fuera de alcance)","text":"<p>La publicaci\u00f3n de la imagen se automatiza mediante el workflow <code>Publish mkdocs image to ACR</code> de GitHub Actions, que env\u00eda la imagen al Azure Container Registry (ACR). Para ello, se deben proporcionar las credenciales adecuadas y validar la ejecuci\u00f3n del proceso.</p> <ol> <li> <p>Rellenar los datos del formulario del workflow con username y pwd del ACR desplegado en Azure.</p> Visualizar usuario y contrase\u00f1a del ACR <p>Siempre puedes ejecutar este comando para recuperar el usuario y la contrase\u00f1a del ACR.</p> <pre><code>az acr credential show --name acrweucp2dev --query \"[username, passwords[0].value]\" -o tsv\n</code></pre> <p></p> </li> <li> <p>Ejecutar workflow y validar la correcta ejecuci\u00f3n del job</p> </li> </ol> <p></p>"},{"location":"informe/evidencias/#validacion-de-imagenes-publicadas","title":"Validaci\u00f3n de imagenes publicadas","text":"<p>Tras publicar las im\u00e1genes por Ansible o por Github Action podremos ver los repositorios en <code>Services/Repositories</code> en el recurso del ACR.</p> <p>Tambi\u00e9n podemos ejectuar el siguiente comando desde local para listar las im\u00e1genes del ACR.</p> <pre><code>az acr repository list --name acrweucp2dev --output table\n</code></pre> <p></p>"},{"location":"informe/evidencias/#imagen-docs-nginx","title":"Imagen <code>docs-nginx</code>","text":""},{"location":"informe/evidencias/#imagen-stackedit","title":"Imagen <code>stackedit</code>","text":""},{"location":"informe/evidencias/#despliegue-en-la-vm","title":"Despliegue en la VM","text":"<p>Para desplegar la imagen de mkdocs-nginx en un contendor sobre la m\u00e1quina virtual ejecutamos el siguiente playbook que contiene el rol <code>vm</code>.</p> <pre><code>ansible-playbook ansible/playbook.yml -i ansible/hosts.yml --extra-vars \"@ansible/vars.yml\" --ask-vault-pass\n</code></pre> <p>Si todo ha ido bien se puede comprobar que el sitio se muestra a trav\u00e9s de internet en la ip p\u00fablica de la VM. Ejecutando el comando:</p> <pre><code>curl -k -u charlstown:*** https://${VM_IP}:443\n</code></pre> <p>Tambi\u00e9n puede visualizarse en el browser en la direcci\u00f3n <code>https://ip-publica/</code>.</p> <p></p> <p>Si introducimos el usuario y la contrase\u00f1a tendremos acceso a la web de la imagen de `` levantada en la IP p\u00fablica de la VM.</p> <p></p>"},{"location":"informe/evidencias/#despliegue-en-el-aks","title":"Despliegue en el AKS","text":"<p>A continuaci\u00f3n se muestran las evidencias de que el despliegue del contenedor en AKS se ha realizado correctamente tras ejecutar el siguiente comando, el cual aplica el rol <code>aks</code>:</p> <pre><code>ansible-playbook playbook_aks.yml -i hosts.yml --ask-vault-pass\n</code></pre> <p>Podemos comprobar que el servicio se ha creado correctamente con tipo <code>LoadBalancer</code> y que la IP p\u00fablica ha sido asignada:</p> <pre><code>kubectl get svc stackedit-service -n cp2\n</code></pre> <p>Resultado:</p> <pre><code>NAME                TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\nstackedit-service   LoadBalancer   10.0.237.2     74.178.201.19   80:32417/TCP   40m\n</code></pre> <p>Esto indica que la aplicaci\u00f3n desplegada est\u00e1 accesible p\u00fablicamente a trav\u00e9s de la IP <code>74.178.201.19</code>.</p> <p>Podemos validar que el contenedor se ha desplegado correctamente y que est\u00e1 sirviendo en el puerto <code>80</code>:</p> <pre><code>kubectl logs -n cp2 -l app=stackedit\n</code></pre> <p>Resultado:</p> <pre><code>HTTP server started: http://localhost:8080\n</code></pre> <p>Por tanto, accediendo desde el navegador a <code>http://74.178.201.19</code> se podr\u00e1 visualizar la interfaz web de StackEdit.</p> <p></p> <p>Esto confirma que el despliegue en AKS se ha realizado con \u00e9xito, con el contenedor sirviendo desde la imagen publicada en el ACR.</p>"},{"location":"informe/evidencias/#comprobacion-de-persistencia","title":"Comprobaci\u00f3n de persistencia","text":"<p>Para validar que el contenedor desplegado en AKS cuenta con almacenamiento persistente, se realiza la siguiente prueba:</p> <ol> <li>Crear una nota desde la interfaz web de StackEdit accediendo a <code>http://74.178.201.19</code>.</li> </ol> <p>Se a\u00f1ade una nueva nota con el siguiente contenido:</p> <pre><code># HelloWorld from the Cloud \ud83d\ude80  \n_\u201cBienvenido al desierto de lo real.\u201d \u2014 Morfeo_\n</code></pre> <p> 2. Eliminar el pod para forzar su recreaci\u00f3n autom\u00e1tica por Kubernetes:</p> <pre><code>kubectl delete pod -n cp2 -l app=stackedit\n</code></pre> <p>Desde Lens podemos ver como se recrea el contenedor.</p> <p> 3. Actualizar la p\u00e1gina web tras unos segundos. La nota deber\u00eda seguir estando presente, lo que confirma que el volumen persistente est\u00e1 funcionando correctamente.</p> <p></p>"},{"location":"informe/licencia/","title":"Licencia","text":"<p>Para este ejercicio se ha utilizado la licencia MIT (Massachusetts Institute of Technology License), una de las licencias m\u00e1s utilizadas en proyectos de c\u00f3digo abierto. La licencia completa puede consultarse en el siguiente enlace al repositorio del proyecto:  </p> <p> Ver archivo LICENSE </p>"},{"location":"informe/licencia/#justificacion-de-la-eleccion-de-la-licencia","title":"Justificaci\u00f3n de la elecci\u00f3n de la licencia","text":"<p>Se ha optado por la licencia MIT debido a su facilidad de implementaci\u00f3n y su compatibilidad con otros modelos de licencia. MIT permite que cualquier persona utilice, copie, modifique y distribuya el c\u00f3digo sin restricciones, siempre y cuando se incluya la atribuci\u00f3n original en el c\u00f3digo fuente (MIT License, s.f.).  </p> <p>La licencia MIT es ampliamente utilizada debido a su simplicidad y flexibilidad. Permite la reutilizaci\u00f3n del c\u00f3digo con m\u00ednimas restricciones, lo que la hace ideal para proyectos de c\u00f3digo abierto que buscan una adopci\u00f3n amplia. Como se\u00f1ala Mahajan (n.d.), la licencia MIT es una de las m\u00e1s permisivas, ya que permite modificaciones y redistribuci\u00f3n con pocas limitaciones, a diferencia de otras como la Apache 2.0, que incluye cl\u00e1usulas adicionales sobre patentes y atribuci\u00f3n.</p>"},{"location":"informe/licencia/#permisos-y-restricciones-de-uso","title":"Permisos y restricciones de uso","text":"<p>La licencia MIT permite lo siguiente:</p> <ul> <li>Uso personal y comercial sin restricciones.  </li> <li>Modificaci\u00f3n y distribuci\u00f3n del c\u00f3digo.  </li> <li>Incorporaci\u00f3n en proyectos de c\u00f3digo abierto o cerrado.  </li> </ul> <p>Sin embargo, impone las siguientes condiciones:</p> <ul> <li>Debe mantenerse el aviso de copyright y la declaraci\u00f3n de licencia en todas las copias o partes sustanciales del software.  </li> <li>No ofrece garant\u00eda ni responsabilidad sobre el uso del software (\"as is\", sin garant\u00eda de funcionalidad o idoneidad).  </li> </ul>"},{"location":"informe/licencia/#texto-completo-de-la-licencia","title":"Texto completo de la licencia","text":"<pre><code>MIT License\n\nCopyright (c) 2025 Carlos Grande\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"},{"location":"informe/referencias/","title":"Referencias","text":"<p>Ansible. (s.f.-a). Best practices for structuring Ansible playbooks. Ansible Documentation. Recuperado de https://docs.ansible.com/ansible/2.8/user_guide/playbooks_best_practices.html</p> <p>Ansible. (s.f.-b). Ansible configuration settings. Ansible Documentation. Recuperado de https://docs.ansible.com/ansible/latest/reference_appendices/config.html</p> <p>Mahajan, J. (n.d.). Simple guide to open source licenses. Medium. Retrieved from https://medium.com/@jayeshmahajan/simple-guide-to-open-source-licenses-ec5b3d29ae80</p> <p>MIT License. (s.f.). MIT License Terms. Recuperado de https://choosealicense.com/licenses/mit/</p> <p>Stivenson, T. (2023). Mejores pr\u00e1cticas en Terraform. Medium. Recuperado de https://medium.com/@tonystivenson1995/mejores-practicas-en-terraform-107533470831</p>"},{"location":"informe/referencias/#herramientas-usadas","title":"Herramientas usadas","text":"<p>JGraph Ltd. (s.f.). draw.io. Recuperado de https://www.drawio.com/</p> <p>MkDocs. (s.f.). MkDocs Documentation. Recuperado de https://www.mkdocs.org</p> <p>Squidfunk. (s.f.). Material for MkDocs. Recuperado de https://squidfunk.github.io/mkdocs-material/</p> <p>StackEdit. (s.f.). StackEdit - In-browser Markdown editor. GitHub. https://github.com/benweet/stackedit</p> <p>WithPDF. (s.f.). WithPDF Plugin for MkDocs. Recuperado de https://github.com/orzih/mkdocs-with-pdf</p>"},{"location":"informe/arquitectura/","title":"Arquitectura","text":"<p>La Arquitectura organiza en dos secciones principales:</p> <ul> <li> Infraestrutura: contiene la descripci\u00f3n de los componentes desplegados con terraform y la justificaci\u00f3n de sus par\u00e1metros.</li> <li> Configuraci\u00f3n de la infraestructura: las configuraciones aplicadas a la infraestructura desplegada, automatizadas con Ansible, y la justificaci\u00f3n de cada una de ellas.</li> </ul>"},{"location":"informe/arquitectura/#vision-general","title":"Visi\u00f3n general","text":"<p>El siguiente diagrama representa la infraestructura desplegada con Terraform y configurada con Ansible, incluyendo una m\u00e1quina virtual con un contenedor Podman y un cl\u00faster AKS, ambos obteniendo im\u00e1genes desde un Azure Container Registry (ACR).</p> <p> </p> <p>Figura 1: Diagrama de la arquitectura desplegada en Azure (Elaboraci\u00f3n propia con draw.io).</p>"},{"location":"informe/arquitectura/configuracion/","title":"Configuraci\u00f3n de la infraestructura","text":"<p>A continuaci\u00f3n se describen las configuraciones aplicadas a la infraestructura desplegada, automatizadas con Ansible, y la justificaci\u00f3n de cada una de ellas.</p>"},{"location":"informe/arquitectura/configuracion/#imagenes-contenerizadas","title":"Im\u00e1genes contenerizadas","text":""},{"location":"informe/arquitectura/configuracion/#imagen-sin-persistencia-para-la-vm","title":"Im\u00e1gen sin persistencia para la VM","text":"<p>La imagen utilizada en el contenedor Podman dentro de la m\u00e1quina virtual se basa en MkDocs, una librer\u00eda de documentaci\u00f3n escrita en Python. Esta herramienta permite generar sitios est\u00e1ticos a partir de archivos Markdown, facilitando la creaci\u00f3n y publicaci\u00f3n de documentaci\u00f3n t\u00e9cnica (MkDocs, s.f.). La imagen generada en este ejercicio contiene la documentaci\u00f3n del propio proyecto, asegurando que el contenido se pueda visualizar de manera estructurada en un navegador.</p> <p>Adem\u00e1s, se ha utilizado el tema Material for MkDocs, que a\u00f1ade una interfaz moderna y varias opciones de personalizaci\u00f3n (Squidfunk, s.f.).</p> <p>La documentaci\u00f3n tambi\u00e9n est\u00e1 disponible a trav\u00e9s de GitHub Pages, lo que permite su acceso incluso cuando la infraestructura de Azure no est\u00e1 desplegada. Se puede visualizar en el siguiente enlace:  </p> <p> Ver documentaci\u00f3n en GitHub Pages </p>"},{"location":"informe/arquitectura/configuracion/#imagen-con-persistencia-para-el-aks","title":"Im\u00e1gen con persistencia para el AKS","text":"<p>La imagen desplegada en el cl\u00faster de AKS est\u00e1 basada en StackEdit, una aplicaci\u00f3n web de c\u00f3digo abierto que permite editar y guardar documentos en formato Markdown directamente desde el navegador. Esta herramienta es ideal para la toma de notas t\u00e9cnicas o redacci\u00f3n de documentaci\u00f3n r\u00e1pida, ya que ofrece previsualizaci\u00f3n en tiempo real y sincronizaci\u00f3n con almacenamiento local y en la nube (StackEdit, s.f.).</p> <p>Para este ejercicio se ha utilizado la imagen p\u00fablica disponible en Docker Hub: <code>benweet/stackedit</code>, la cual se despliega en un contenedor dentro de Kubernetes con un volumen persistente asociado. Esto garantiza que el contenido creado por el usuario, como notas o documentos, no se pierde aunque el contenedor se reinicie o se reprograme, validando as\u00ed la persistencia de los datos en un entorno din\u00e1mico.</p>"},{"location":"informe/arquitectura/configuracion/#configuracion-con-ansible","title":"Configuraci\u00f3n con Ansible","text":"<p>Para la configuraci\u00f3n y automatizaci\u00f3n del despliegue en la infraestructura se ha utilizado Ansible, organizando las tareas en roles espec\u00edficos, siguiendo las buenas pr\u00e1cticas recomendadas en la documentaci\u00f3n oficial de Ansible Ansible. (s.f.-a).</p> <p>La ejecuci\u00f3n de los archivos est\u00e1 estructurada de la siguiente manera:</p> <pre><code>ansible\n\u251c\u2500\u2500 hosts.tmpl           # Plantilla del inventario din\u00e1mico\n\u251c\u2500\u2500 playbook.yml         # Orquesta todos los roles\n\u251c\u2500\u2500 publish_images.yml   # Publica im\u00e1genes en el ACR\n\u251c\u2500\u2500 vm_deployment.yml    # Despliega en el contenedor de la VM\n\u251c\u2500\u2500 aks_deployment.yml   # Despliega en el contenedor del AKS\n\u251c\u2500\u2500 roles\n\u2502   \u251c\u2500\u2500 acr              # Rol para la publicaci\u00f3n en el ACR\n\u2502   \u2514\u2500\u2500 vm               # Rol para la configuraci\u00f3n de la VM\n\u2502   \u2514\u2500\u2500 aks              # Rol para la configuraci\u00f3n de la VM\n\u251c\u2500\u2500 secrets.yml          # Variables sensibles\n\u2514\u2500\u2500 vars.yml             # Variables generales del despliegue\n</code></pre> <ul> <li>ACR: Gestiona la publicaci\u00f3n de im\u00e1genes en Azure Container Registry (ACR), construyendo y empujando im\u00e1genes desde la VM y desde la m\u00e1quina local.  </li> <li>VM: Configura la m\u00e1quina virtual, instalando Podman, desplegando el contenedor con MkDocs, gestionando autenticaciones y asegurando la persistencia con Systemd.  </li> <li>AKS (no presente en este esquema, pero estructurable de forma similar): Se encargar\u00eda de desplegar aplicaciones en Azure Kubernetes Service (AKS).</li> </ul>"},{"location":"informe/arquitectura/configuracion/#rol-acr","title":"Rol ACR","text":"<p>Para configurar el ACR se publicar\u00e1n dos im\u00e1genes contenerizadas: una corresponde a un sitio est\u00e1tico en Nginx, que ser\u00e1 desplegado en una m\u00e1quina virtual con Podman, y la otra es una aplicaci\u00f3n con persistencia que ser\u00e1 ejecutada en un contenedor dentro de Azure Kubernetes Service (AKS).</p> <p>Puedes ver las evidencias de este rol en el  siguiente enlace.</p> <p>Este proyecto permite la publicaci\u00f3n de las im\u00e1genes en el ACR de dos maneras:</p> <ul> <li>Publicaci\u00f3n mediante Ansible.</li> <li>Publicaci\u00f3n manual mediante Github Actions (fuera de alcance).</li> </ul> <p>Para la publicaci\u00f3n usando Ansible se ha generado un rol llamado <code>acr</code> que contiene todas las tareas necesarias y se estructura de la siguiente manera:</p> <pre><code>ansible/\n\u251c\u2500\u2500 roles/\n\u2502   \u251c\u2500\u2500 acr/                        # Rol para gestionar ACR en Ansible\n\u2502   \u2502   \u251c\u2500\u2500 tasks/                  # Tareas que se ejecutan en el ACR\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 main.yml            # Inclusi\u00f3n de todas las tareas\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 install.yml         # Instala podman en la VM\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 build_docs.yml      # Construcci\u00f3n de las im\u00e1genes\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 login.yml           # Iniciar sesi\u00f3n en ACR\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 push_mkdocs.yml     # Publicaci\u00f3n de mkdocs en ACR\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 push_stackedit.yml  # Publicaci\u00f3n de stackedit en ACR\n\u2502   \u2502   \u2514\u2500\u2500 vars/                   # Variables espec\u00edficas del rol\n\u2502   \u2502       \u2514\u2500\u2500 main.yml            # Configuraci\u00f3n de par\u00e1metros\n</code></pre> <p>El fichero <code>tasks/main.yml</code> dentro del rol acr, gestiona la configuraci\u00f3n y publicaci\u00f3n de im\u00e1genes en la m\u00e1quina virtual y el Azure Container Registry (ACR).</p> main.yml<pre><code>---\n- name: Install Podman on the VM\n  include_tasks: install.yml\n\n- name: Build MkDocs image\n  include_tasks: build_docs.yml\n\n- name: Login into ACR from the VM\n  include_tasks: login.yml\n\n- name: Push mkdocs image to ACR from the VM\n  include_tasks: push_mkdocs.yml\n\n- name: Push stackedit image to ACR from localhost\n  include_tasks: push_stackedit.yml\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#instalar-podman","title":"Instalar Podman","text":"<p>Esta tarea instala Podman en la m\u00e1quina virtual asegur\u00e1ndose de que est\u00e9 disponible en el sistema. Adem\u00e1s, actualiza la cach\u00e9 de paquetes antes de la instalaci\u00f3n.</p> install.yml<pre><code>---\n- name: Install Podman\n  apt:\n    name: podman\n    state: present\n    update_cache: yes\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#construir-imagen-mkdocs","title":"Construir imagen mkdocs","text":"<p>Clona el repositorio del proyecto en la m\u00e1quina virtual, instala dependencias necesarias para MkDocs y WeasyPrint, construye el sitio est\u00e1tico de MkDocs y genera una imagen de contenedor con Podman basada en el <code>Dockerfile.docs</code>.</p> build_docs.yml<pre><code>---\n- name: Ensure repository is present on the VM\n  git:\n    repo: \"https://github.com/charlstown/unir-cp2.git\"\n    dest: \"/opt/unir-cp2\"\n    version: main\n\n- name: Install dependencies for MkDocs\n  apt:\n    name:\n      - python3-pip\n    state: present\n    update_cache: no\n  become: yes\n\n- name: Install required system dependencies for WeasyPrint\n  apt:\n    name:\n      - libpango1.0-0\n      - libpangocairo-1.0-0\n      - libcairo2\n    state: present\n    update_cache: no\n  become: yes\n\n- name: Install project dependencies\n  pip:\n    requirements: \"/opt/unir-cp2/requirements.txt\"\n\n- name: Build MkDocs static site\n  command:\n    cmd: mkdocs build\n    chdir: \"/opt/unir-cp2\"\n\n- name: Build Podman image on the VM\n  command:\n    cmd: podman build -t \"{{ image_name_docs }}:{{ image_tag_docs }}\" -f /opt/unir-cp2/Dockerfile.docs\n    chdir: \"/opt/unir-cp2\"\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#login-en-el-acr","title":"Login en el ACR","text":"<p>Realiza la autenticaci\u00f3n en Azure Container Registry (ACR) desde la m\u00e1quina virtual utilizando Podman, empleando credenciales de usuario y contrase\u00f1a.</p> login_acr.yml<pre><code>---\n- name: Log in to ACR from the VM\n  command: &gt;\n    podman login {{ acr_login_server }} \n    -u {{ acr_username }} \n    --password {{ acr_password }}\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#publicar-imagen-mkdocs-nginx","title":"Publicar imagen <code>mkdocs-nginx</code>","text":"<p>Etiqueta la imagen generada de MkDocs con el formato adecuado para ACR y la sube al registro de contenedores de Azure desde la m\u00e1quina virtual.</p> push_mkdocs.yml<pre><code>---\n# Push MkDocs image\n- name: Tag MkDocs image for ACR\n  command: &gt;\n    podman tag {{ image_name_docs }}:{{ image_tag_docs }} \n    {{ acr_login_server }}/{{ image_name_docs }}:{{ image_tag_docs }}\n\n- name: Push MkDocs image to ACR from the VM\n  command: &gt;\n    podman push {{ acr_login_server }}/{{ image_name_docs }}:{{ image_tag_docs }}\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#publicar-imagen-stackedit","title":"Publicar imagen <code>stackedit</code>","text":"<p>Descarga la imagen <code>stackedit-base</code> desde Docker Hub, la etiqueta para el ACR y finalmente la sube al registro de Azure.</p> push_stackedit.yml<pre><code>---\n- name: Pull StackEdit image from Docker Hub\n  command: &gt;\n    podman pull docker.io/benweet/stackedit-base:latest\n  become: yes\n\n- name: Tag StackEdit image for ACR\n  command: &gt;\n    podman tag docker.io/benweet/stackedit-base:latest {{ acr_name }}.azurecr.io/{{ image_name_stackedit }}:{{ image_tag_stackedit }}\n  become: yes\n\n- name: Push StackEdit image to ACR\n  command: &gt;\n    podman push {{ acr_name }}.azurecr.io/{{ image_name_stackedit }}:{{ image_tag_stackedit }}\n  become: yes\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#rol-vm","title":"Rol VM","text":"<p>Para la publicaci\u00f3n usando Ansible se ha generado un rol llamado <code>vm</code> que contiene todas las tareas necesarias y se estructura de la siguiente manera:</p> <pre><code>ansible/\n\u251c\u2500\u2500 roles\n\u2502   \u251c\u2500\u2500 vm\n\u2502   \u2502   \u251c\u2500\u2500 handlers\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 main.yml\n\u2502   \u2502   \u251c\u2500\u2500 tasks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 auth.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 container.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 main.yml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 systemd.yml\n\u2502   \u2502   \u2514\u2500\u2500 vars\n\u2502   \u2502       \u2514\u2500\u2500 main.yml\n</code></pre> <p>Puedes ver las evidencias de este rol en el  siguiente enlace.</p> <p>El fichero <code>tasks/main.yml</code> dentro del rol acr, gestiona la configuraci\u00f3n y publicaci\u00f3n de im\u00e1genes en la m\u00e1quina virtual y el Azure Container Registry (ACR).</p> main.yml<pre><code>- name: Include authentication setup\n  import_tasks: auth.yml\n\n- name: Include container deployment\n  import_tasks: container.yml\n\n- name: Include systemd configuration\n  import_tasks: systemd.yml\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#autenticacion-basica","title":"Autenticaci\u00f3n b\u00e1sica","text":"<p>En esta tarea se configura autenticaci\u00f3n b\u00e1sica en Nginx mediante <code>htpasswd</code>, asegurando que solo usuarios autorizados puedan acceder. Se instala Apache Utils, se crea el directorio de autenticaci\u00f3n y se genera un archivo de credenciales.</p> <pre><code>---\n- name: Install Apache Utils for htpasswd\n  apt:\n    name: apache2-utils\n    state: present\n  become: yes\n\n- name: Ensure authentication directory exists\n  file:\n    path: /etc/nginx/auth\n    state: directory\n    mode: '0755'\n\n- name: Load secure variables\n  include_vars: secrets.yml\n\n- name: Generate htpasswd file\n  command: htpasswd -bc /etc/nginx/auth/htpasswd.users charlstown \"{{ site_pwd }}\"\n  args:\n    creates: /etc/nginx/auth/htpasswd.users\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#desplegar-contenedor","title":"Desplegar contenedor","text":"<p>En esta tarea se inicia sesi\u00f3n en el ACR para descargar la imagen del contenedor y se ejecuta con soporte SSL y autenticaci\u00f3n b\u00e1sica, vinculando el archivo de credenciales generado en el paso anterior.</p> <pre><code>---\n- name: Log into Azure Container Registry (ACR)\n  containers.podman.podman_login:\n    registry: \"{{ acr_name }}.azurecr.io\"\n    username: \"{{ acr_username }}\"\n    password: \"{{ acr_password }}\"\n\n- name: Run container from ACR image with SSL and Basic Auth\n  containers.podman.podman_container:\n    name: mkdocs_container\n    image: \"{{ acr_name }}.azurecr.io/{{ image_name }}:{{ image_tag }}\"\n    state: started\n    restart_policy: always\n    ports:\n      - \"443:443\"\n    volume:\n      - \"/etc/nginx/auth/htpasswd.users:/etc/nginx/.htpasswd:ro\"\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#disponibilidad-como-servicio","title":"Disponibilidad como servicio","text":"<p>En esta tarea se convierte el contenedor en un servicio systemd, esto garantiza la disponibilidad continua del servicio sin intervenci\u00f3n manual, ya que systemd lo monitorea y lo vuelve a iniciar si detecta que ha dejado de funcionar.</p> <pre><code>---\n- name: Generate systemd service for Podman container\n  containers.podman.podman_generate_systemd:\n    name: mkdocs_container\n    dest: /etc/systemd/system/\n    restart_policy: always\n\n- name: Enable and start Podman container systemd service\n  systemd:\n    name: container-mkdocs_container\n    enabled: yes\n    state: started\n    daemon_reload: yes\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#rol-aks","title":"Rol AKS","text":"<p>Para el despliegue de la aplicaci\u00f3n en el cl\u00faster de Kubernetes mediante Ansible se ha generado un rol llamado <code>aks</code>, que contiene todas las tareas necesarias y se estructura de la siguiente manera:</p> <pre><code>ansible/\n\u251c\u2500\u2500 roles\n\u2502   \u251c\u2500\u2500 aks\n\u2502   \u2502   \u251c\u2500\u2500 tasks\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 acr_auth.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 deploy.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 main.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 namespace.yml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pvc.yml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service.yml\n\u2502   \u2502   \u251c\u2500\u2500 templates\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 acr-auth.json.j2\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 deployment.yml.j2\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 pvc.yml.j2\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service.yml.j2\n\u2502   \u2502   \u2514\u2500\u2500 vars\n\u2502   \u2502       \u2514\u2500\u2500 main.yml\n</code></pre> <p>Puedes ver las evidencias de este rol en el  siguiente enlace.</p> <p>El fichero <code>tasks/main.yml</code> dentro del rol <code>aks</code> orquesta todas las tareas necesarias para desplegar la aplicaci\u00f3n, incluyendo la creaci\u00f3n del namespace, los vol\u00famenes persistentes, el despliegue de los contenedores y el servicio de acceso.</p> main.yml<pre><code>- name: Create Kubernetes Namespace\n  import_tasks: namespace.yml\n\n- name: Create ACR Secret in Kubernetes\n  import_tasks: acr_auth.yml\n\n- name: Apply PersistentVolumeClaim\n  import_tasks: pvc.yml\n\n- name: Deploy Application\n  import_tasks: deploy.yml\n\n- name: Create LoadBalancer Service\n  import_tasks: service.yml\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#crear-namespace","title":"Crear Namespace","text":"<p>Esta tarea se encarga de crear el namespace donde se desplegar\u00e1n todos los recursos de la aplicaci\u00f3n dentro del cl\u00faster de AKS, asegurando su aislamiento l\u00f3gico del resto de workloads.</p> namespace.yml<pre><code>---\n- name: Create Kubernetes Namespace\n  kubernetes.core.k8s:\n    name: \"{{ namespace }}\"\n    api_version: v1\n    kind: Namespace\n    state: present\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#crear-secreto-en-el-acr","title":"Crear secreto en el ACR","text":"<p>Esta tarea crea un <code>Secret</code> en el cl\u00faster de AKS con las credenciales necesarias para acceder al Azure Container Registry (ACR), permitiendo que Kubernetes pueda descargar im\u00e1genes privadas.</p> acr_auth.yml<pre><code>- name: Create ACR Secret in Kubernetes\n  kubernetes.core.k8s:\n    state: present\n    namespace: \"{{ namespace }}\"\n    definition:\n      apiVersion: v1\n      kind: Secret\n      metadata:\n        name: acr-secret\n      type: kubernetes.io/dockerconfigjson\n      data:\n        .dockerconfigjson: \"{{ lookup('template', 'acr-auth.json.j2') | from_yaml | to_json | b64encode }}\"\n</code></pre> <p>El secreto se genera a partir de la plantilla <code>acr-auth.json.j2</code>, que contiene las credenciales codificadas en base64:</p> acr-auth.json.j2<pre><code>{\n  \"auths\": {\n    \"{{ acr_name }}.azurecr.io\": {\n      \"username\": \"{{ acr_username }}\",\n      \"password\": \"{{ acr_password }}\",\n      \"auth\": \"{{ (acr_username + ':' + acr_password) | b64encode }}\"\n    }\n  }\n}\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#crear-volumen-persistente","title":"Crear volumen persistente","text":"<p>Esta tarea crea un <code>PersistentVolumeClaim</code> en el cl\u00faster de AKS, necesario para mantener los datos persistentes entre reinicios del contenedor.</p> pvc.yml<pre><code>- name: Apply PersistentVolumeClaim\n  kubernetes.core.k8s:\n    state: present\n    namespace: \"{{ namespace }}\"\n    definition: \"{{ lookup('template', 'pvc.yml.j2') }}\"\n</code></pre> <p>La plantilla utilizada define un volumen de 5GiB con acceso en modo lectura-escritura por un \u00fanico nodo:</p> pvc.yml.j2<pre><code>---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: {{ pvc_name }}\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n</code></pre>"},{"location":"informe/arquitectura/configuracion/#desplegar-aplicacion","title":"Desplegar aplicaci\u00f3n","text":"<p>Esta tarea aplica el <code>Deployment</code> de Kubernetes necesario para ejecutar la aplicaci\u00f3n StackEdit. Se especifica la imagen publicada en el ACR, el puerto interno del contenedor, el volumen persistente y las credenciales de acceso al registro.</p> deploy.yml<pre><code>- name: Deploy Application\n  kubernetes.core.k8s:\n    state: present\n    namespace: \"{{ namespace }}\"\n    definition: \"{{ lookup('template', 'deployment.yml.j2') }}\"\n</code></pre> <p>La plantilla del manifiesto define una r\u00e9plica del contenedor con puerto interno <code>8080</code> y volumen montado en <code>/data</code>:</p> deployment.yml.j2<pre><code>---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: stackedit\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: stackedit\n  template:\n    metadata:\n      labels:\n        app: stackedit\n    spec:\n      containers:\n      - name: stackedit\n        image: \"{{ acr_name }}.azurecr.io/{{ image_name_stackedit }}:{{ image_tag_stackedit }}\"\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: storage\n          mountPath: \"/data\"\n        env:\n        - name: ENV_VAR\n          value: \"example-value\"\n      volumes:\n      - name: storage\n        persistentVolumeClaim:\n          claimName: {{ pvc_name }}\n      imagePullSecrets:\n      - name: acr-secret\n</code></pre>"},{"location":"informe/arquitectura/infraestructura/","title":"Infraestructura","text":"<p>A continuaci\u00f3n se describen los diferentes componentes de la infraestructura desplegados con terraform y la justificaci\u00f3n de sus configuraciones.</p>"},{"location":"informe/arquitectura/infraestructura/#estructura-de-ficheros-terraform","title":"Estructura de ficheros Terraform","text":"<p>Para la implementaci\u00f3n de la infraestructura, se ha seguido una organizaci\u00f3n modular en Terraform, siguiendo las mejores pr\u00e1cticas recomendadas en la comunidad (Stivenson, 2023). A continuaci\u00f3n, se describe la estructura de los archivos y su prop\u00f3sito dentro del proyecto.</p> <pre><code>terraform/\n\u251c\u2500\u2500 main.tf           # Archivo principal que llama a los m\u00f3dulos y recursos\n\u251c\u2500\u2500 modules/          # Carpeta que contiene los m\u00f3dulos de infraestructura\n\u2502   \u251c\u2500\u2500 acr/          # M\u00f3dulo para desplegar Azure Container Registry (ACR)\n\u2502   \u251c\u2500\u2500 aks/          # M\u00f3dulo para desplegar Azure Kubernetes Service (AKS)\n\u2502   \u2514\u2500\u2500 vm/           # M\u00f3dulo para desplegar la m\u00e1quina virtual en Azure\n\u251c\u2500\u2500 outputs.tf        # Define las salidas (outputs) de Terraform\n\u251c\u2500\u2500 terraform.tfvars  # Define valores espec\u00edficos para esta implementaci\u00f3n\n\u2514\u2500\u2500 vars.tf           # Define las variables requeridas para el despliegue\n</code></pre>"},{"location":"informe/arquitectura/infraestructura/#fichero-principal-maintf","title":"Fichero principal <code>main.tf</code>","text":"<p>El archivo main.tf define la infraestructura base del proyecto y se estructura en tres secciones principales:</p> <ul> <li>Configuraci\u00f3n base: define el proveedor azurerm, el grupo de recursos y variables locales para el entorno.</li> <li>Llamada a los m\u00f3dulos: incluyendo la m\u00e1quina virtual (VM), el registro de contenedores (ACR) y el cl\u00faster de Kubernetes (AKS).</li> <li>Generaci\u00f3n din\u00e1mica del inventario de Ansible: crea autom\u00e1ticamente un archivo hosts.yml con la informaci\u00f3n de conexi\u00f3n necesaria para la configuraci\u00f3n mediante Ansible.</li> </ul>"},{"location":"informe/arquitectura/infraestructura/#configuracion-base","title":"Configuraci\u00f3n base","text":"main.tf<pre><code>terraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~&gt;3.0\"\n    }\n  }\n}\n\n# Configuraci\u00f3n del proveedor de Azure\nprovider \"azurerm\" {\n  subscription_id = \"fb24fc1f-67e2-4871-8be2-c10a36e74c93\"\n  features {}\n}\n\n# Define la variable de entorno elegida para el despliegue\nlocals {\n  env_suffix = \"-${var.environment}\"\n}\n\n# Crear un grupo de recursos en West Europe\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = \"${var.resource_group_name}-${var.environment}\"\n  location = var.location\n  tags     = var.tags\n}\n</code></pre>"},{"location":"informe/arquitectura/infraestructura/#llamada-a-modulos","title":"Llamada a m\u00f3dulos","text":"<p>Contiene la llamada a los diferentes m\u00f3dulos de infraestructura, incluyendo la m\u00e1quina virtual (VM), el registro de contenedores (ACR) y el cl\u00faster de Kubernetes (AKS).</p> <p>A continuaci\u00f3n, se muestra un ejemplo de la estructura de un m\u00f3dulo en main.tf, en este caso, la definici\u00f3n del AKS:</p> main.tf<pre><code># Llamar al m\u00f3dulo del AKS\nmodule \"aks\" {\n  source          = \"./modules/aks\"\n  aks_name        = \"${var.aks_name}-${var.environment}\"\n  resource_group  = azurerm_resource_group.rg.name\n  location        = azurerm_resource_group.rg.location\n  dns_prefix      = var.dns_prefix\n  node_count      = var.node_count\n  vm_size         = var.aks_vm_size\n  acr_id          = module.container_registry.acr_id\n  tags            = var.tags\n}\n</code></pre>"},{"location":"informe/arquitectura/infraestructura/#generacion-del-inventario","title":"Generaci\u00f3n del inventario","text":"<p>La generaci\u00f3n del inventario de Ansible se realiza din\u00e1micamente con Terraform para automatizar la configuraci\u00f3n de la infraestructura. Se emplea el recurso <code>local_file</code> para crear el archivo <code>hosts.yml</code> basado en una plantilla que incluye informaci\u00f3n clave de los recursos desplegados:</p> <ul> <li>M\u00e1quina virtual: Direcci\u00f3n IP p\u00fablica, usuario y clave SSH.</li> <li>Azure Container Registry (ACR): Nombre, servidor de login, credenciales de acceso.</li> <li>Cl\u00faster AKS: Nombre y grupo de recursos asociado.</li> </ul> main.tf<pre><code># Generar el archivo hosts.yml\nresource \"local_file\" \"ansible_inventory\" {\n  filename = \"../ansible/hosts.yml\"\n  content  = templatefile(\"../ansible/hosts.tmpl\", {\n    vm_name             = var.vm_name\n    vm_public_ip        = module.virtual_machine.vm_public_ip\n    vm_username         = var.vm_username\n    ssh_private_key     = \"~/.ssh/az_unir_rsa\"\n    python_interpreter  = var.python_interpreter\n    acr_name            = \"${var.acr_name}${var.environment}\"\n    acr_login_server    = \"${var.acr_name}${var.environment}.azurecr.io\"\n    acr_username        = module.container_registry.acr_username\n    acr_password        = module.container_registry.acr_password\n    aks_name            = var.aks_name\n    aks_resource_group  = var.resource_group_name\n  })\n</code></pre> <p>Esta instrucci\u00f3n de terraform apunta al fichero <code>hosts.tmpl</code> de la carpeta de ansible y que usa como plantilla para generar el fichero de inventario <code>hosts.yml</code>.</p> hosts.tmpl<pre><code>all:\n  children:\n    azure_vm:\n      hosts:\n        ${vm_name}:\n          ansible_host: ${vm_public_ip}\n          ansible_user: ${vm_username}\n          ansible_ssh_private_key_file: ${ssh_private_key}\n          ansible_python_interpreter: ${python_interpreter}\n\n    azure_acr:\n      hosts:\n        ${acr_name}:\n          acr_login_server: ${acr_login_server}\n\n    azure_aks:\n      hosts:\n        ${aks_name}:\n          aks_resource_group: ${aks_resource_group}\n          ansible_connection: local\n          ansible_python_interpreter: /usr/bin/python3\n</code></pre> <p>Esto permite que Ansible trabaje con informaci\u00f3n actualizada sin intervenci\u00f3n manual, garantizando coherencia y simplificando la configuraci\u00f3n.</p>"},{"location":"informe/arquitectura/infraestructura/#fichero-terraformtfvars","title":"Fichero <code>terraform.tfvars</code>","text":"<p>El fichero define las variables utilizadas en el despliegue de la infraestructura, priorizando configuraciones de bajo coste para optimizar el uso de recursos en el ejercicio. </p> <p>Se establece un entorno de desarrollo (<code>dev</code>), una m\u00e1quina virtual con especificaciones m\u00ednimas y un cl\u00faster AKS con un solo nodo. Adem\u00e1s, se configura un ACR y una red con una subred peque\u00f1a para evitar sobreasignaci\u00f3n de recursos innecesaria.</p> terraform.tfvars<pre><code># Generic\nresource_group_name = \"rg-weu-cp2\"\nlocation            = \"West Europe\"\nenvironment         = \"dev\"\n\n# ACR\nacr_name            = \"acrweucp2\"\n\n# virtual machine\nvm_name             = \"vm-weu-cp2-docs\"\nvm_username         = \"charlstown\"\nvm_size             = \"Standard_B1ms\"   # \"Standard_B1ls\"\nssh_public_key      = \"~/.ssh/az_unir_rsa.pub\"\npython_interpreter  = \"/usr/bin/python3\"\n\n# Networking\nvnet_name           = \"vnet-weu-cp2\"\nsubnet_name         = \"subnet-weu-cp2\"\nsubnet_cidr         = \"10.0.1.0/28\"\n\n# Image\nimage_os            = \"22_04-lts-gen2\"\nimage_offer         = \"0001-com-ubuntu-server-jammy\"\n# check offers here: https://documentation.ubuntu.com/azure/en/latest/azure-how-to/instances/find-ubuntu-images/\n\n# AKS\naks_name            = \"aks-weu-cp2\"\ndns_prefix          = \"aksweucp2\"\nnode_count          = 1\naks_vm_size         = \"Standard_B2s\"\n\n# Tags\ntags = {\n  environment = \"casopractico2\"\n}\n</code></pre>"},{"location":"informe/arquitectura/infraestructura/#modulos","title":"M\u00f3dulos","text":""},{"location":"informe/arquitectura/infraestructura/#container-registry","title":"Container registry","text":"<p>La infraestructura de Azure Container Service(ACR) se ha definido utilizando Terraform, organizando los recursos en m\u00f3dulos separados para mejorar la modularidad y reutilizaci\u00f3n del c\u00f3digo. A continuaci\u00f3n, se presentan los archivos principales que definen el despliegue:</p> <pre><code>terraform/\n\u2502\u2500\u2500 terraform.tfvars        # Variables globales del despliegue\n\u2502\u2500\u2500 main.tf                 # Llamada a m\u00f3dulos y recursos principales\n\u2502\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 acr/                # M\u00f3dulo del ACR\n\u2502   \u2502   \u251c\u2500\u2500 main.tf         # Definici\u00f3n del ACR\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf      # Variables de salida\n\u2502   \u2502   \u2514\u2500\u2500 variables.tf    # Definici\u00f3n de variables del m\u00f3dulo\n</code></pre> <p>Puedes ver las evidencias de este despliegue en el  siguiente enlace.</p>"},{"location":"informe/arquitectura/infraestructura/#fichero-maintf","title":"Fichero <code>main.tf</code>","text":"<p>El fichero <code>main.tf</code> del m\u00f3dulo del ACR recoge \u00fanicamente el recurso <code>azurerm_container_registry</code>.</p> main.tf<pre><code># Crear Azure Container Registry (ACR)\nresource \"azurerm_container_registry\" \"acr\" {\n  name                = var.acr_name\n  resource_group_name = var.resource_group\n  location            = var.location\n  sku                 = \"Basic\"  # Opci\u00f3n m\u00e1s barata\n  admin_enabled       = true\n  tags                = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.acr_name</code> Define el nombre del registro de contenedores. Se usa una variable para permitir reutilizaci\u00f3n y facilitar la personalizaci\u00f3n sin modificar el c\u00f3digo. <code>var.resource_group</code> Especifica el grupo de recursos donde se desplegar\u00e1 el ACR. <code>var.location</code> Indica la regi\u00f3n de Azure en la que se despliega el registro. <code>sku = \"Basic\"</code> Se elige el nivel Basic, ya que es la opci\u00f3n m\u00e1s econ\u00f3mica y suficiente para los requisitos del ejercicio. Alternativamente, se podr\u00eda usar <code>Standard</code> o <code>Premium</code> si se requiriera mayor escalabilidad o funcionalidades adicionales. <code>admin_enabled = true</code> Habilita el acceso mediante credenciales de administrador. Se activa para simplificar la autenticaci\u00f3n en el entorno de pruebas, aunque en entornos de producci\u00f3n ser\u00eda recomendable deshabilitarlo y usar autenticaci\u00f3n con identidades de Azure AD. <code>tags = var.tags</code> Permite agregar metadatos al recurso para organizaci\u00f3n y clasificaci\u00f3n dentro de Azure."},{"location":"informe/arquitectura/infraestructura/#maquina-virtual","title":"M\u00e1quina virtual","text":"<p>La infraestructura de la m\u00e1quina virtual se ha definido utilizando Terraform, organizando los recursos en m\u00f3dulos separados para mejorar la modularidad y reutilizaci\u00f3n del c\u00f3digo. A continuaci\u00f3n, se presentan los archivos principales que definen el despliegue:</p> <pre><code>terraform/\n\u2502\u2500\u2500 terraform.tfvars        # Variables globales del despliegue\n\u2502\u2500\u2500 main.tf                 # Llamada a m\u00f3dulos y recursos principales\n\u2502\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 vm/                 # M\u00f3dulo de la m\u00e1quina virtual\n\u2502   \u2502   \u251c\u2500\u2500 main.tf         # Definici\u00f3n de la VM\n\u2502   \u2502   \u251c\u2500\u2500 network.tf      # Configuraci\u00f3n de la red\n\u2502   \u2502   \u251c\u2500\u2500 security.tf     # Reglas de seguridad (NSG)\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf      # Variables de salida (IPs, VM ID)\n\u2502   \u2502   \u2514\u2500\u2500 variables.tf    # Definici\u00f3n de variables del m\u00f3dulo\n</code></pre> <p>Puedes ver las evidencias de este despliegue en el  siguiente enlace.</p>"},{"location":"informe/arquitectura/infraestructura/#fichero-maintf_1","title":"Fichero <code>main.tf</code>","text":"<p>El fichero <code>main.tf</code> del m\u00f3dulo de la m\u00e1quina virtual recoge los siguientes recursos:</p> <ul> <li>IP P\u00fablica \u2192 Asigna una direcci\u00f3n IP fija a la VM para acceso remoto.  </li> <li>Interfaz de Red (NIC) \u2192 Proporciona conectividad a la m\u00e1quina virtual en la red definida.  </li> <li>M\u00e1quina Virtual (VM) \u2192 Instancia de un sistema operativo en Azure con configuraci\u00f3n personalizada.  </li> </ul>"},{"location":"informe/arquitectura/infraestructura/#ip-publica","title":"IP P\u00fablica","text":"main.tf<pre><code>resource \"azurerm_public_ip\" \"vm_public_ip\" {\n  name                = \"${var.vm_name}-public-ip\"\n  resource_group_name = var.resource_group\n  location            = var.location\n  allocation_method   = \"Static\"\n  tags                = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.vm_name</code> Se usa para nombrar la IP p\u00fablica de la VM de manera \u00fanica dentro del recurso. <code>var.resource_group</code> Grupo de recursos en el que se despliega la IP p\u00fablica. <code>var.location</code> Regi\u00f3n de Azure donde se asignar\u00e1 la IP. <code>allocation_method = \"Static\"</code> Se usa IP est\u00e1tica para mantener una direcci\u00f3n fija y evitar cambios en reinicios. <code>var.tags</code> Se a\u00f1aden etiquetas para organizaci\u00f3n y clasificaci\u00f3n dentro de Azure."},{"location":"informe/arquitectura/infraestructura/#interfaz-de-red-nic","title":"Interfaz de Red (NIC)","text":"main.tf<pre><code>resource \"azurerm_network_interface\" \"nic\" {\n  name                = \"${var.vm_name}-nic\"\n  resource_group_name = var.resource_group\n  location            = var.location\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.subnet.id\n    public_ip_address_id          = azurerm_public_ip.vm_public_ip.id\n    private_ip_address_allocation = \"Dynamic\"\n  }\n  tags = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.vm_name</code> Nombre de la interfaz de red, vinculado a la VM. <code>var.resource_group</code> Grupo de recursos donde se crea la NIC. <code>var.location</code> Regi\u00f3n donde se despliega la interfaz. <code>var.subnet_id</code> Identificador de la subred a la que se conecta la NIC. <code>var.public_ip_address_id</code> Asigna la IP p\u00fablica est\u00e1tica previamente definida. <code>private_ip_address_allocation = \"Dynamic\"</code> Permite que Azure asigne autom\u00e1ticamente una IP privada a la VM. <code>var.tags</code> Se incluyen etiquetas para organizaci\u00f3n."},{"location":"informe/arquitectura/infraestructura/#maquina-virtual-linux","title":"M\u00e1quina Virtual Linux","text":"main.tf<pre><code>resource \"azurerm_linux_virtual_machine\" \"vm\" {\n  name                  = var.vm_name\n  resource_group_name   = var.resource_group\n  location              = var.location\n  size                  = var.vm_size\n  admin_username        = var.admin_username\n  network_interface_ids = [azurerm_network_interface.nic.id]\n\n  admin_ssh_key {\n    username   = var.admin_username\n    public_key = var.ssh_public_key\n  }\n\n  os_disk {\n    caching              = \"ReadWrite\"\n    storage_account_type = \"Standard_LRS\"\n  }\n\n  source_image_reference {\n    publisher = \"Canonical\"\n    offer     = var.image_offer\n    sku       = var.image_os\n    version   = \"latest\"\n  }\n  tags = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.vm_name</code> Nombre de la m\u00e1quina virtual. <code>var.resource_group</code> Grupo de recursos en el que se despliega la VM. <code>var.location</code> Regi\u00f3n donde se despliega la m\u00e1quina. <code>var.vm_size</code> Tipo de m\u00e1quina virtual seleccionada para optimizar coste y rendimiento. <code>var.admin_username</code> Usuario administrador de la VM. <code>var.ssh_public_key</code> Clave p\u00fablica SSH para autenticaci\u00f3n sin contrase\u00f1a. <code>var.network_interface_ids</code> Conecta la VM a la interfaz de red creada. <code>caching = \"ReadWrite\"</code> Optimizaci\u00f3n del rendimiento del disco del sistema. <code>storage_account_type = \"Standard_LRS\"</code> Tipo de almacenamiento del disco OS, seleccionado por costo y disponibilidad. <code>var.image_offer</code> Imagen de sistema operativo en el Azure Marketplace. <code>var.image_os</code> Versi\u00f3n espec\u00edfica del sistema operativo (<code>Ubuntu 22.04 LTS</code>). <code>var.tags</code> Etiquetas para gesti\u00f3n y organizaci\u00f3n dentro de Azure."},{"location":"informe/arquitectura/infraestructura/#fichero-networktf","title":"Fichero <code>network.tf</code>","text":"<p>El fichero <code>network.tf</code> del m\u00f3dulo de la m\u00e1quina virtual recoge los siguientes recursos:  </p> <ul> <li>Red Virtual (VNet) \u2192 Define el espacio de direcciones y la conectividad general.  </li> <li>Subred \u2192 Segmenta la red dentro de la VNet, optimizando la asignaci\u00f3n de direcciones IP.</li> </ul>"},{"location":"informe/arquitectura/infraestructura/#red-virtual-vnet","title":"Red Virtual (VNet)","text":"network.tf<pre><code>resource \"azurerm_virtual_network\" \"vnet\" {\n  name                = var.vnet_name\n  resource_group_name = var.resource_group\n  location            = var.location\n  address_space       = [\"10.0.0.0/16\"]\n  tags                = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.vnet_name</code> Nombre de la red virtual, definido como variable para flexibilidad. <code>var.resource_group</code> Grupo de recursos donde se despliega la VNet. <code>var.location</code> Regi\u00f3n de Azure donde se crea la red. <code>address_space = [\"10.0.0.0/16\"]</code> Espacio de direcciones IP asignado a la red virtual, lo que permite futuras segmentaciones. <code>var.tags</code> Etiquetas opcionales para organizaci\u00f3n y gesti\u00f3n en Azure."},{"location":"informe/arquitectura/infraestructura/#subred","title":"Subred","text":"network.tf<pre><code>resource \"azurerm_subnet\" \"subnet\" {\n  name                 = var.subnet_name\n  resource_group_name  = var.resource_group\n  virtual_network_name = azurerm_virtual_network.vnet.name\n  address_prefixes     = [var.subnet_cidr]\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.subnet_name</code> Nombre de la subred dentro de la VNet. <code>var.resource_group</code> Grupo de recursos en el que se define la subred. <code>var.virtual_network_name</code> Relaci\u00f3n con la red virtual a la que pertenece la subred. <code>address_prefixes = [var.subnet_cidr]</code> Define el rango de direcciones IP asignado a la subred (<code>10.0.1.0/28</code>), optimizando el uso de IPs."},{"location":"informe/arquitectura/infraestructura/#fichero-securitytf","title":"Fichero <code>security.tf</code>","text":"<p>El fichero <code>security.tf</code> del m\u00f3dulo de la m\u00e1quina virtual recoge los siguientes recursos:</p> <ul> <li>Grupo de Seguridad de Red (NSG) \u2192 Gestiona las reglas de tr\u00e1fico para la m\u00e1quina virtual.  </li> <li>Reglas de Seguridad (Security Rules) \u2192 Permiten o bloquean tr\u00e1fico en puertos espec\u00edficos.</li> </ul>"},{"location":"informe/arquitectura/infraestructura/#grupo-de-seguridad-de-red-nsg","title":"Grupo de Seguridad de Red (NSG)","text":"security.tf<pre><code>resource \"azurerm_network_security_group\" \"vm_nsg\" {\n  name                = \"${var.vm_name}-nsg\"\n  resource_group_name = var.resource_group\n  location            = var.location\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.vm_name</code> Nombre del grupo de seguridad, vinculado a la VM. <code>var.resource_group</code> Grupo de recursos donde se crea el NSG. <code>var.location</code> Regi\u00f3n de Azure donde se despliega el NSG."},{"location":"informe/arquitectura/infraestructura/#regla-para-permitir-ssh-puerto-22","title":"Regla para permitir SSH (Puerto 22)","text":"security.tf<pre><code>resource \"azurerm_network_security_rule\" \"allow_ssh\" {\n  name                        = \"Allow-SSH\"\n  priority                    = 1000\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"22\"\n  source_address_prefix       = \"*\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.vm_nsg.name\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>priority = 1000</code> Asigna una prioridad alta para esta regla. <code>direction = \"Inbound\"</code> Define que la regla aplica al tr\u00e1fico entrante. <code>access = \"Allow\"</code> Permite el tr\u00e1fico en el puerto 22. <code>protocol = \"Tcp\"</code> Especifica que la regla aplica a conexiones TCP. <code>destination_port_range = \"22\"</code> Permite el acceso SSH a la VM."},{"location":"informe/arquitectura/infraestructura/#regla-para-permitir-http-puerto-80","title":"Regla para permitir HTTP (Puerto 80)","text":"security.tf<pre><code>resource \"azurerm_network_security_rule\" \"allow_http\" {\n  name                        = \"Allow-HTTP\"\n  priority                    = 1010\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"80\"\n  source_address_prefix       = \"*\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.vm_nsg.name\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>priority = 1010</code> Define la prioridad de la regla para HTTP. <code>destination_port_range = \"80\"</code> Habilita tr\u00e1fico en el puerto 80 para servir contenido web."},{"location":"informe/arquitectura/infraestructura/#regla-para-permitir-https-puerto-443","title":"Regla para permitir HTTPS (Puerto 443)","text":"security.tf<pre><code>resource \"azurerm_network_security_rule\" \"allow_https\" {\n  name                        = \"Allow-HTTPS\"\n  priority                    = 1020\n  direction                   = \"Inbound\"\n  access                      = \"Allow\"\n  protocol                    = \"Tcp\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"443\"\n  source_address_prefix       = \"*\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.vm_nsg.name\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>priority = 1020</code> Prioridad asignada a la regla HTTPS. <code>destination_port_range = \"443\"</code> Habilita tr\u00e1fico en el puerto 443 para conexiones seguras."},{"location":"informe/arquitectura/infraestructura/#regla-para-permitir-todo-el-trafico-de-salida","title":"Regla para permitir todo el tr\u00e1fico de salida","text":"security.tf<pre><code>resource \"azurerm_network_security_rule\" \"allow_outbound\" {\n  name                        = \"Allow-All-Outbound\"\n  priority                    = 900\n  direction                   = \"Outbound\"\n  access                      = \"Allow\"\n  protocol                    = \"*\"\n  source_port_range           = \"*\"\n  destination_port_range      = \"*\"\n  source_address_prefix       = \"*\"\n  destination_address_prefix  = \"*\"\n  network_security_group_name = azurerm_network_security_group.vm_nsg.name\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>priority = 900</code> Define una prioridad m\u00e1s baja que las reglas de entrada. <code>direction = \"Outbound\"</code> Aplica la regla al tr\u00e1fico saliente. <code>access = \"Allow\"</code> Permite que la VM se comunique con otros servicios. <code>protocol = \"*\"</code> Permite cualquier protocolo. <code>destination_port_range = \"*\"</code> No restringe los puertos de destino."},{"location":"informe/arquitectura/infraestructura/#kubernetes-service-aks","title":"Kubernetes service (AKS)","text":"<p>La infraestructura del Azure Kubernetes Service (AKS) se ha definido en Terraform dentro de un m\u00f3dulo independiente para asegurar una correcta organizaci\u00f3n y reutilizaci\u00f3n del c\u00f3digo. Este m\u00f3dulo define los recursos necesarios para desplegar un cl\u00faster de Kubernetes gestionado por Azure.</p> <pre><code>terraform/\n\u2502\u2500\u2500 terraform.tfvars        # Variables globales del despliegue\n\u2502\u2500\u2500 main.tf                 # Llamada a m\u00f3dulos y recursos principales\n\u2502\u2500\u2500 modules/\n\u2502   \u251c\u2500\u2500 aks/                # M\u00f3dulo de Kubernetes Service (AKS)\n\u2502   \u2502   \u251c\u2500\u2500 main.tf         # Definici\u00f3n del cl\u00faster de Kubernetes\n\u2502   \u2502   \u251c\u2500\u2500 outputs.tf      # Variables de salida (Cluster ID, Node Pool ID)\n\u2502   \u2502   \u2514\u2500\u2500 variables.tf    # Definici\u00f3n de variables del m\u00f3dulo\n</code></pre> <p>Puedes ver las evidencias de este despliegue en el  siguiente enlace.</p>"},{"location":"informe/arquitectura/infraestructura/#fichero-maintf_2","title":"Fichero <code>main.tf</code>","text":"<p>El fichero <code>main.tf</code> del m\u00f3dulo de AKS incluye los siguientes recursos:</p> <ul> <li>Cl\u00faster de Kubernetes (AKS) \u2192 Crea una instancia de Azure Kubernetes Service con un node pool por defecto y acceso RBAC habilitado.</li> <li>Role Assignment para ACR \u2192 Permite a AKS acceder al Azure Container Registry (ACR) para extraer im\u00e1genes de contenedores.</li> </ul>"},{"location":"informe/arquitectura/infraestructura/#cluster-de-kubernetes-aks","title":"Cl\u00faster de Kubernetes (AKS)","text":"main.tf<pre><code>resource \"azurerm_kubernetes_cluster\" \"aks\" {\n  name                = var.aks_name\n  location            = var.location\n  resource_group_name = var.resource_group\n  dns_prefix          = var.dns_prefix\n  sku_tier            = \"Standard\"\n\n  default_node_pool {\n    name            = \"default\"\n    node_count      = var.node_count\n    vm_size         = var.vm_size\n    os_disk_size_gb = 30\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  role_based_access_control_enabled = true\n\n  tags = var.tags\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.aks_name</code> Nombre del cl\u00faster de AKS. <code>var.resource_group</code> Grupo de recursos donde se despliega el AKS. <code>var.location</code> Regi\u00f3n de Azure donde se despliega. <code>var.dns_prefix</code> Prefijo DNS \u00fanico del cl\u00faster. <code>sku_tier = \"Standard\"</code> Define el nivel del servicio de Kubernetes. <code>default_node_pool</code> Define el grupo de nodos (Node Pool) que ejecutar\u00e1 los contenedores. <code>var.node_count</code> N\u00famero de nodos en el node pool por defecto. <code>var.vm_size</code> Tama\u00f1o de las m\u00e1quinas virtuales utilizadas como nodos. <code>os_disk_size_gb = 30</code> Tama\u00f1o del disco de cada nodo. <code>identity { type = \"SystemAssigned\" }</code> Se asigna una identidad gestionada para que el cl\u00faster pueda autenticarse con otros servicios de Azure. <code>role_based_access_control_enabled = true</code> Habilita RBAC para gestionar permisos dentro del cl\u00faster. <code>var.tags</code> Etiquetas para organizaci\u00f3n y gesti\u00f3n dentro de Azure."},{"location":"informe/arquitectura/infraestructura/#role-assignment-para-acr","title":"Role Assignment para ACR","text":"main.tf<pre><code>resource \"azurerm_role_assignment\" \"acr_pull\" {\n  scope                = var.acr_id\n  role_definition_name = \"AcrPull\"\n  principal_id         = azurerm_kubernetes_cluster.aks.identity[0].principal_id\n}\n</code></pre> Par\u00e1metro Descripci\u00f3n <code>var.acr_id</code> ID del Azure Container Registry asociado al cl\u00faster. <code>role_definition_name = \"AcrPull\"</code> Asigna el rol de AcrPull, que permite a AKS extraer im\u00e1genes de contenedores desde ACR. <code>principal_id</code> Se refiere a la identidad asignada al cl\u00faster de AKS para la autenticaci\u00f3n con ACR."}]}